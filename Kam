############################################################
# What Drives Engagement in Gaming Videos? (KreekCraft)
# FULL SCRIPT with Train/Test Split
# - uses kreek_numeric.csv + kreek_dataset.csv
# - Linear, Logistic, Multinomial (different IVs)
# - Train/Test evaluation, metrics, and graphs
############################################################

# ------------------ 0. Load Libraries ------------------

# Run once if needed:
# install.packages("tidyverse")
# install.packages("nnet")

library(tidyverse)
library(nnet)
library(ggplot2)

# ------------------ 1. Manual AUC Function (no pROC) ------------------

auc_manual <- function(labels, scores) {
  lbl <- ifelse(labels %in% c(1, "1"), 1, 0)
  
  ord <- order(scores, decreasing = TRUE)
  lbl <- lbl[ord]
  
  cum_pos <- cumsum(lbl)
  cum_neg <- cumsum(1 - lbl)
  
  total_pos <- max(cum_pos)
  total_neg <- max(cum_neg)
  
  if (total_pos == 0 || total_neg == 0) return(NA_real_)
  
  tpr <- cum_pos / total_pos
  fpr <- cum_neg / total_neg
  
  dfpr   <- diff(fpr)
  tprmid <- (tpr[-1] + tpr[-length(tpr)]) / 2
  
  sum(dfpr * tprmid)
}

# ------------------ 2. Load BOTH Data Files ------------------

kreek_num <- read.csv("/Users/walnut/Downloads/kreek_numeric.csv")
kreek_raw <- read.csv("/Users/walnut/Downloads/kreek_dataset.csv")

cat("Rows numeric :", nrow(kreek_num), "\n")
cat("Rows raw     :", nrow(kreek_raw), "\n")

# ------------------ 3. Merge Files (row-aligned) ------------------

extra_cols <- setdiff(names(kreek_raw), names(kreek_num))
df_full <- cbind(kreek_num, kreek_raw[extra_cols])

cat("Rows merged  :", nrow(df_full), "\n")

# ------------------ 4. Clean & Convert Variables ------------------

df_full$engagement_binary <- factor(df_full$engagement_binary, levels = c(0, 1))

df_full$engagement_multinom <- factor(
  df_full$engagement_ord,
  levels = c("Low", "Medium", "High", "Very High"),
  ordered = FALSE
)

df_full$game_title <- as.factor(df_full$game_title)

# Ensure title_length exists and is numeric
if (!"title_length" %in% names(df_full)) {
  if ("Title" %in% names(df_full)) {
    df_full$title_length <- nchar(df_full$Title)
  } else {
    stop("No 'title_length' or 'Title' column found. Create a title length variable first.")
  }
} else {
  df_full$title_length <- as.numeric(df_full$title_length)
}

# ------------------ 5. Build Modeling Dataset ------------------

df_model <- df_full %>%
  dplyr::select(
    engagement,
    engagement_binary,
    engagement_multinom,
    Duration,
    title_length,
    has_all_caps,
    has_exclamation,
    has_question,
    has_period,
    has_comma,
    has_plus,
    has_pipe,
    game_title
  ) %>%
  filter(complete.cases(.))

cat("\nRows after cleaning:", nrow(df_model), "\n")
table(df_model$engagement_binary)
table(df_model$engagement_multinom)

# ------------------ 6. Train/Test Split ------------------

set.seed(123)  # for reproducibility
n <- nrow(df_model)
train_idx <- sample(seq_len(n), size = round(0.7 * n))

train <- df_model[train_idx, ]
test  <- df_model[-train_idx, ]

cat("\nTrain rows:", nrow(train), " Test rows:", nrow(test), "\n")

############################################################
# 7. MODEL 1: LINEAR REGRESSION (continuous engagement)
#    IVs: Duration + title_length + punctuation + game_title
############################################################

lm_model <- lm(
  engagement ~ Duration + title_length +
    has_exclamation + has_question + has_period +
    game_title,
  data = train
)

cat("\n================ Linear Regression (Train) ========\n")
summary(lm_model)

# Evaluate on TEST set
test$lm_pred <- predict(lm_model, newdata = test)

lm_rmse <- sqrt(mean((test$engagement - test$lm_pred)^2))
lm_mae  <- mean(abs(test$engagement - test$lm_pred))

cat("\nLinear Regression Test RMSE:", round(lm_rmse, 5), "\n")
cat("Linear Regression Test MAE :", round(lm_mae, 5), "\n")

############################################################
# 8. MODEL 2: LOGISTIC REGRESSION (high vs low engagement)
#    IVs: style features (different IV set)
############################################################

log_model <- glm(
  engagement_binary ~
    has_all_caps + has_comma + has_plus + has_pipe + title_length,
  data   = train,
  family = binomial
)

cat("\n================ Logistic Regression (Train) ======\n")
summary(log_model)

cat("\nOdds Ratios (Logistic Regression):\n")
print(exp(coef(log_model)))

# Predict on TEST set
test$log_pred_prob  <- predict(log_model, newdata = test, type = "response")
test$log_pred_class <- factor(ifelse(test$log_pred_prob >= 0.5, 1, 0), levels = c(0, 1))

cm_log <- table(Predicted = test$log_pred_class, Actual = test$engagement_binary)
cat("\n==== Logistic Regression Confusion Matrix (Test) ====\n")
print(cm_log)

TP <- cm_log["1", "1"]
TN <- cm_log["0", "0"]
FP <- cm_log["1", "0"]
FN <- cm_log["0", "1"]

log_accuracy  <- (TP + TN) / sum(cm_log)
log_precision <- TP / (TP + FP)
log_recall    <- TP / (TP + FN)
log_f1        <- 2 * (log_precision * log_recall) / (log_precision + log_recall)

cat("\n==== Logistic Regression Metrics (Test) ====\n")
cat("Accuracy :", round(log_accuracy, 4), "\n")
cat("Precision:", round(log_precision, 4), "\n")
cat("Recall   :", round(log_recall, 4), "\n")
cat("F1 Score :", round(log_f1, 4), "\n")

log_auc <- auc_manual(test$engagement_binary, test$log_pred_prob)
cat("AUC (manual, Test):", round(log_auc, 4), "\n")

############################################################
# 9. MODEL 3: MULTINOMIAL REGRESSION (4 engagement levels)
#    IVs: punctuation + duration + title_length (different again)
############################################################

multi_model <- multinom(
  engagement_multinom ~
    has_exclamation + has_all_caps + Duration + title_length,
  data  = train,
  trace = FALSE
)

cat("\n================ Multinomial Regression (Train) ===\n")
summary(multi_model)

cat("\nOdds Ratios (Multinomial Regression):\n")
print(exp(coef(multi_model)))

# Predict on TEST set
test$multi_pred_class <- predict(multi_model, newdata = test)

cm_multi <- table(Predicted = test$multi_pred_class,
                  Actual    = test$engagement_multinom)

cat("\n==== Multinomial Regression Confusion Matrix (Test) ====\n")
print(cm_multi)

multi_accuracy <- sum(diag(cm_multi)) / sum(cm_multi)
cat("\nOverall Multinomial Accuracy (Test):", round(multi_accuracy, 4), "\n")

############################################################
# 10. GRAPHS (ggplot)
############################################################

## 1) Engagement vs Duration (whole dataset) ##
ggplot(df_model, aes(x = Duration, y = engagement)) +
  geom_point(alpha = 0.3, color = "#0073C2") +
  geom_smooth(method = "loess", color = "red", size = 1) +
  labs(
    title = "Relationship Between Duration and Engagement",
    x = "Duration (seconds)",
    y = "Engagement Rate"
  ) +
  theme_minimal()

## 2) Engagement by Game Title (whole dataset) ##
ggplot(df_model, aes(x = game_title, y = engagement, fill = game_title)) +
  geom_boxplot() +
  labs(
    title = "Engagement by Game Title",
    x = "Game Title",
    y = "Engagement"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

## 3) Impact of ALL CAPS (whole dataset) ##
ggplot(df_model, aes(x = factor(has_all_caps), y = engagement, fill = factor(has_all_caps))) +
  geom_violin(alpha = 0.5) +
  geom_boxplot(width = 0.15) +
  labs(
    title = "Impact of ALL CAPS on Engagement",
    x = "Has ALL CAPS (0 = No, 1 = Yes)",
    y = "Engagement"
  ) +
  theme_minimal()

## 4) Distribution of Engagement Levels (whole dataset) ##
ggplot(df_model, aes(x = engagement_multinom, fill = engagement_multinom)) +
  geom_bar() +
  labs(
    title = "Distribution of Engagement Levels",
    x = "Engagement Category",
    y = "Count"
  ) +
  theme_minimal()

## 5) Predicted Probability of High Engagement (Logistic, Test) ##
ggplot(test, aes(x = log_pred_prob)) +
  geom_histogram(bins = 50, fill = "#00A2FF", alpha = 0.6) +
  labs(
    title = "Predicted Probability of High Engagement (Test Set)",
    x = "Predicted Probability",
    y = "Frequency"
  ) +
  theme_minimal()

## 6) Predicted Engagement Categories (Multinomial, Test) ##
ggplot(test, aes(x = multi_pred_class, fill = multi_pred_class)) +
  geom_bar() +
  labs(
    title = "Predicted Engagement Categories (Multinomial Model, Test Set)",
    x = "Predicted Category",
    y = "Count"
  ) +
  theme_minimal()

## 7) ACTUAL vs PREDICTED (Multinomial, Test) ##
df_actual_pred <- test %>%
  mutate(
    actual    = engagement_multinom,
    predicted = multi_pred_class
  )

ggplot(df_actual_pred, aes(x = actual, fill = predicted)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Actual vs Predicted Engagement Levels (Multinomial, Test Set)",
    x = "Actual Category",
    y = "Count",
    fill = "Predicted"
  ) +
  theme_minimal()

## 8) Confusion Matrix Heatmap (Multinomial, Test) ##
cm_df <- as.data.frame(cm_multi)
colnames(cm_df) <- c("Predicted", "Actual", "Freq")

ggplot(cm_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 5) +
  scale_fill_gradient(low = "white", high = "purple") +
  labs(
    title = "Confusion Matrix Heatmap (Multinomial, Test Set)",
    x = "Predicted Category",
    y = "Actual Category"
  ) +
  theme_minimal()

## 9) ACTUAL vs PREDICTED (Logistic, Test) ##
df_log_plot <- test %>%
  mutate(
    actual    = engagement_binary,
    predicted = log_pred_class
  )

ggplot(df_log_plot, aes(x = actual, fill = predicted)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Actual vs Predicted (Binary Logistic Model, Test Set)",
    x = "Actual Class",
    y = "Count",
    fill = "Predicted"
  ) +
  theme_minimal()

## 10) Logistic ROC Curve (Test, manual AUC) ##
df_roc <- test %>%
  arrange(desc(log_pred_prob)) %>%
  mutate(
    actual_num = ifelse(engagement_binary == 1, 1, 0),
    tp = cumsum(actual_num),
    fp = cumsum(1 - actual_num),
    fn = sum(actual_num)      - tp,
    tn = sum(1 - actual_num)  - fp,
    tpr = tp / (tp + fn),
    fpr = fp / (fp + tn)
  )

ggplot(df_roc, aes(x = fpr, y = tpr)) +
  geom_line(color = "blue", size = 1) +
  geom_abline(linetype = "dashed") +
  labs(
    title = paste("ROC Curve (Test Set, AUC =", round(log_auc, 4), ")"),
    x = "False Positive Rate",
    y = "True Positive Rate"
  ) +
  theme_minimal()

############################################################
# END OF SCRIPT
############################################################
